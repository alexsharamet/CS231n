{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read From File\n",
    "dataSet = unpickle(\"data_batch_1\")\n",
    "labels=dataSet[b'labels']\n",
    "data=dataSet[b'data']\n",
    "filenames=dataSet[b'filenames']\n",
    "MaxSize=1000 #10000 max\n",
    "labels=labels[:MaxSize]\n",
    "data=data[:MaxSize]\n",
    "filenames=filenames[:MaxSize]\n",
    "\n",
    "data=data/255\n",
    "\n",
    "#Train/Test Split\n",
    "X_all, X_test, y_all, y_test = train_test_split(data,labels,test_size=0.2,random_state=0)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_all,y_all,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "middle_layer=100\n",
    "W1 = np.random.rand(middle_layer,3072)\n",
    "W2 = np.random.rand(10,middle_layer)\n",
    "W1 = W1*1e-6\n",
    "W2 = W2*1e-6\n",
    "W1 = np.asmatrix(W1)\n",
    "W2 = np.asmatrix(W2)\n",
    "B1=np.asmatrix(np.zeros(100)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Additional Functions\n",
    "def f(W,x):\n",
    "    row=np.asmatrix(x)\n",
    "    ans=W*row.T\n",
    "    return ans\n",
    "\n",
    "def MtrxPrint(M):\n",
    "    n,m = M.shape\n",
    "    print(n,m)\n",
    "    for i in range(n):\n",
    "        for j in range(10):\n",
    "            print(M[i,j],' ',end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forwardPredict(W2,W1,b1,x):\n",
    "    #input layer\n",
    "    s=np.maximum(0,f(W1,x)+b1)\n",
    "    #hidden layer\n",
    "    ans=np.asarray(softmax(f(W2,s.T)))\n",
    "    predict=np.argmax(ans)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SoftMaxLoss(x,y):\n",
    "    return -np.log(softmax(x)[y])\n",
    "\n",
    "def GradientNumericVector(x,y):\n",
    "    eps=1e-5\n",
    "    grad=np.zeros(10)\n",
    "    lsS=SoftMaxLoss(x,y)\n",
    "    for i in range(10):\n",
    "        xt=x.copy()\n",
    "        xt[i]+=eps\n",
    "        ls=SoftMaxLoss(xt,y)\n",
    "        grad[i]=(ls-lsS)/eps\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backPropLossI(W2,W1,b1,x,y,DW2,DW1,Db1):\n",
    "#forward\n",
    "    #input layer\n",
    "    inp=f(W1,x)+b1\n",
    "    s=np.maximum(inp,0)\n",
    "    \n",
    "    #hidden layer\n",
    "    hd=f(W2,s.T)\n",
    "    \n",
    "    #softmax\n",
    "    ex=np.exp(hd)\n",
    "    \n",
    "    #print(ex)\n",
    "    sm=np.sum(ex)\n",
    "    if(sm<1e-5):\n",
    "        sm=1e-5\n",
    "    LossI=-np.log(ex[y]/sm)\n",
    "    \n",
    "#backward\n",
    "    #DLossI=1\n",
    "    Dsm=1/sm\n",
    "    \n",
    "    Dhd=ex*Dsm\n",
    "    Dhd[y]-=1\n",
    "\n",
    "    Ds=Dhd.T*W2\n",
    "    \n",
    "    DhdT=np.asarray(Dhd.T).flatten()\n",
    "    n=np.shape(W2)[0]\n",
    "    for i in range(n):\n",
    "        DW2[i]=s.T*float(DhdT[i])\n",
    "    \n",
    "    Dinp=np.asarray(Ds.copy())\n",
    "    Dinp=Dinp.flatten()\n",
    "    for i in range(np.shape(Dinp)[0]):\n",
    "        if inp[i]<=0:\n",
    "            Dinp[i]=0\n",
    "            \n",
    "    Db1=Dinp\n",
    "    n=np.shape(W1)[0]\n",
    "    for i in range(n):\n",
    "        DW1[i]=x*float(Dinp.T[i])\n",
    "    return LossI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientStep(X,Y,W2,W1,B1,learning_rate):\n",
    "    DW1_g = np.zeros(middle_layer*3072)\n",
    "    DW1_g=np.resize(DW1_g,[middle_layer,3072])\n",
    "    DW2_g = np.zeros(10*middle_layer)\n",
    "    DW2_g=np.resize(DW2_g,[10,middle_layer])\n",
    "    Db1_g=np.asmatrix(np.zeros(100)).T\n",
    "    \n",
    "    N=len(Y)\n",
    "    Loss=0\n",
    "    for i in range(N):\n",
    "        #init new gradients matrix\n",
    "        DW1 = np.zeros(middle_layer*3072)\n",
    "        DW1=np.resize(DW1,[middle_layer,3072])\n",
    "        DW2 = np.zeros(10*middle_layer)\n",
    "        DW2=np.resize(DW2_g,[10,middle_layer])\n",
    "        Db1=np.asmatrix(np.zeros(100)).T\n",
    "        \n",
    "        Loss+=backPropLossI(W2,W1,B1,X[i],Y[i],DW2,DW1,Db1)\n",
    "        DW1_g+=DW1\n",
    "        DW2_g+=DW2\n",
    "        Db1_g+=Db1\n",
    "    \n",
    "    \n",
    "    W1-=learning_rate*DW1_g/N\n",
    "    W2-=learning_rate*DW2_g/N\n",
    "    B1-=learning_rate*Db1_g/N\n",
    "    #B2=0 (analitic)\n",
    "    return Loss/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def postProcess(W2,W1,B1):\n",
    "    n,m = np.shape(W2)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if W2.item(i,j)>10:\n",
    "                W2.itemset((i,j),10)\n",
    "                \n",
    "    n,m = np.shape(W1)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if W1.item(i,j)>10:\n",
    "                W1.itemset((i,j),10)\n",
    "                \n",
    "    n = np.shape(B1)[0]\n",
    "    for i in range(n):\n",
    "        if B1.item(i)>10:\n",
    "            B1.itemset(i,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DW1 = np.zeros(middle_layer*3072)\n",
    "DW1=np.resize(DW1,[middle_layer,3072])\n",
    "DW2 = np.zeros(10*middle_layer)\n",
    "DW2=np.resize(DW2,[10,middle_layer])\n",
    "Db1=np.asmatrix(np.zeros(100)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2.3025851]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(GradientNumericVector(x,0))\n",
    "#print(SoftMaxLoss(x,0))\n",
    "backPropLossI(W2,W1,B1,X_test[0],0,DW2,DW1,Db1)\n",
    "#MtrxPrint(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate = 0.01 Loss = [[ 1.54278464]]\n",
      "Loss= [[ 1.54221499]]  change= [[ 0.00056965]]\n",
      "Loss= [[ 1.54166906]]  change= [[ 0.00054593]]\n",
      "Loss= [[ 1.54109749]]  change= [[ 0.00057157]]\n",
      "Loss= [[ 1.54053856]]  change= [[ 0.00055893]]\n",
      "Loss= [[ 1.53996506]]  change= [[ 0.00057351]]\n",
      "Loss= [[ 1.53942036]]  change= [[ 0.0005447]]\n",
      "Loss= [[ 1.53885385]]  change= [[ 0.00056651]]\n",
      "Loss= [[ 1.53829452]]  change= [[ 0.00055933]]\n",
      "Loss= [[ 1.53773207]]  change= [[ 0.00056245]]\n",
      "Loss= [[ 1.53718853]]  change= [[ 0.00054354]]\n",
      "Loss= [[ 1.53661421]]  change= [[ 0.00057432]]\n",
      "Loss= [[ 1.53605643]]  change= [[ 0.00055778]]\n",
      "Loss= [[ 1.53549716]]  change= [[ 0.00055928]]\n",
      "Loss= [[ 1.53494433]]  change= [[ 0.00055283]]\n",
      "Loss= [[ 1.53439684]]  change= [[ 0.00054749]]\n",
      "Loss= [[ 1.5338361]]  change= [[ 0.00056073]]\n",
      "Loss= [[ 1.53328237]]  change= [[ 0.00055373]]\n",
      "Loss= [[ 1.5327188]]  change= [[ 0.00056357]]\n",
      "Loss= [[ 1.53216925]]  change= [[ 0.00054956]]\n",
      "Loss= [[ 1.53163189]]  change= [[ 0.00053736]]\n",
      "Loss= [[ 1.53105977]]  change= [[ 0.00057212]]\n",
      "Loss= [[ 1.53052367]]  change= [[ 0.0005361]]\n",
      "Loss= [[ 1.52994561]]  change= [[ 0.00057806]]\n",
      "Loss= [[ 1.52939845]]  change= [[ 0.00054716]]\n",
      "Loss= [[ 1.52883768]]  change= [[ 0.00056077]]\n",
      "Loss= [[ 1.52828959]]  change= [[ 0.00054809]]\n",
      "Loss= [[ 1.52773041]]  change= [[ 0.00055918]]\n",
      "Loss= [[ 1.52718836]]  change= [[ 0.00054205]]\n",
      "Loss= [[ 1.5266386]]  change= [[ 0.00054976]]\n",
      "Loss= [[ 1.52610018]]  change= [[ 0.00053842]]\n",
      "Loss= [[ 1.52553836]]  change= [[ 0.00056182]]\n",
      "Loss= [[ 1.52501373]]  change= [[ 0.00052463]]\n",
      "Loss= [[ 1.52445622]]  change= [[ 0.00055752]]\n",
      "Loss= [[ 1.52390186]]  change= [[ 0.00055436]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-712eefa2bc0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rate =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Loss =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mafter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradientStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mchange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mafter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mafter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-4377883bff6a>\u001b[0m in \u001b[0;36mgradientStep\u001b[0;34m(X, Y, W2, W1, B1, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mDb1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mLoss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mbackPropLossI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDW2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mDW1_g\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mDW1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mDW2_g\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mDW2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-6e2b9e66b2f0>\u001b[0m in \u001b[0;36mbackPropLossI\u001b[0;34m(W2, W1, b1, x, y, DW2, DW1, Db1)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mDW1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDinp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mLossI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#learning_rate=1e-3\n",
    "#for i in range(200):\n",
    "#    print(gradientStep(X_test,y_test,W2,W1,B1,learning_rate))\n",
    "#    postProcess(W2,W1,B1)\n",
    "\n",
    "eps=1e-5\n",
    "learning_rate=1e-2\n",
    "while learning_rate > 1e-5:\n",
    "    before=gradientStep(X_test,y_test,W2,W1,B1,learning_rate)\n",
    "    print(\"rate =\",learning_rate,\"Loss =\",before)\n",
    "    while True:\n",
    "        after=gradientStep(X_test,y_test,W2,W1,B1,learning_rate)\n",
    "        change=before-after\n",
    "        before=after\n",
    "        print(\"Loss=\",after,\" change=\",change)\n",
    "        if change < 0:\n",
    "            break;\n",
    "        if change < 1e-5:\n",
    "            break;        \n",
    "    learning_rate/=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.44500\n"
     ]
    }
   ],
   "source": [
    "good=0\n",
    "for i in range(len(X_test)):\n",
    "    ans=forwardPredict(W2,W1,B1,X_test[i])\n",
    "    if(ans == y_test[i]):\n",
    "        good+=1\n",
    "print(\"%10.5f\"% (good/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0929149729373\n",
      "0.0122083352346\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(W2))\n",
    "print(np.max(W1))\n",
    "print(np.max(B1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59,  43,  50, ..., 140,  84,  72], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
